[
  {
    "id": "2602.22289v1",
    "title": "What Topological and Geometric Structure Do Biological Foundation Models Learn? Evidence from 141 Hypotheses",
    "authors": [
      "Ihor Kendiukhov"
    ],
    "published_date": "2026-02-25T14:33:24Z",
    "abstract": "When biological foundation models such as scGPT and Geneformer process single-cell gene expression, what geometric and topological structure forms in their internal representations? Is that structure biologically meaningful or a training artifact, and how confident should we be in such claims? We address these questions through autonomous large-scale hypothesis screening: an AI-driven executor-brainstormer loop that proposed, tested, and refined 141 geometric and topological hypotheses across 52 iterations, covering persistent homology, manifold distances, cross-model alignment, community structure, and directed topology, all with explicit null controls and disjoint gene-pool splits. Three principal findings emerge. First, the models learn genuine geometric structure. Gene embedding neighborhoods exhibit non-trivial topology, with persistent homology significant in 11 of 12 transformer layers at p < 0.05 in the weakest domain and 12 of 12 in the other two. A multi-level distance hierarchy shows that manifold-aware metrics outperform Euclidean distance for identifying regulatory gene pairs, and graph community partitions track known transcription factor target relationships. Second, this structure is shared across independently trained models. CCA alignment between scGPT and Geneformer yields canonical correlation of 0.80 and gene retrieval accuracy of 72 percent, yet none of 19 tested methods reliably recover gene-level correspondences. The models agree on the global shape of gene space but not on precise gene placement. Third, the structure is more localized than it first appears. Under stringent null controls applied across all null families, robust signal concentrates in immune tissue, while lung and external lung signals weaken substantially.",
    "pdf_link": "https://arxiv.org/pdf/2602.22289v1",
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "q-bio.GN"
    ],
    "tldr": "Autonomous hypothesis screening finds biological foundation models scGPT and Geneformer learn genuine, partially shared geometric and topological gene-embedding structure, confirmed via persistent homology and manifold analysis.",
    "keywords": [
      "Persistent Homology",
      "Geodesic Manifold Distance Metric",
      "Canonical Correlation Analysis (CCA)",
      "Transformer Embeddings",
      "Community Structure Detection"
    ],
    "relevance_score": 10
  },
  {
    "id": "2602.23269v1",
    "title": "An Active Learning Framework for Data-Efficient, Human-in-the-Loop Enzyme Function Prediction",
    "authors": [
      "Ashley Babjac",
      "Adrienne Hoarfrost"
    ],
    "published_date": "2026-02-26T17:42:06Z",
    "abstract": "Generalizable protein function prediction is increasingly constrained by the growing mismatch between exponentially expanding sequences of environmental proteins and the comparatively slow accumulation of experimentally verified functional data. Active learning offers a promising path forward for accelerating biological function prediction, by selecting the most informative proteins to experimentally annotate for data-efficient training, yet its potential remains largely unexplored. We introduce HATTER (Human-in-the-loop Adaptive Toolkit for Transferable Enzyme Representations), a modular framework that integrates multiple active learning strategies with human-in-the-loop experimental annotation to efficiently fine tune function prediction models. We compare active learning training to standard supervised training for biological enzyme function prediction, demonstrating that active learning achieves performance comparable to standard training across diverse protein sequence evaluation datasets while requiring fewer model updates, processing less data, and substantially reducing computational cost. Interestingly, point-based uncertainty sampling methods like entropy or margin sampling perform as well or better than more complex acquisition functions such as bayesian sampling or BALD, highlighting the relative importance of sequence diversity in training datasets and model architecture design. These results demonstrate that human-in-the-loop active learning can efficiently accelerate enzyme discovery, providing a flexible platform for adaptive, scalable, and expert-guided protein function prediction.",
    "pdf_link": "https://arxiv.org/pdf/2602.23269v1",
    "categories": [
      "q-bio.QM"
    ],
    "tldr": "HATTER, a human-in-the-loop active learning framework, matches supervised enzyme-function prediction using less data, showing entropy/margin uncertainty sampling rivals complex acquisition functions like BALD.",
    "keywords": [
      "Entropy-Based Uncertainty Sampling",
      "Margin Sampling Strategy",
      "Environmental Protein Sequence Encoder",
      "Bayesian Active Learning By Disagreement (BALD)",
      "Fine-Tuned Enzyme Representation Model"
    ],
    "relevance_score": 9
  },
  {
    "id": "2602.22263v1",
    "title": "CryoNet.Refine: A One-step Diffusion Model for Rapid Refinement of Structural Models with Cryo-EM Density Map Restraints",
    "authors": [
      "Fuyao Huang",
      "Xiaozhu Yu",
      "Kui Xu",
      "Qiangfeng Cliff Zhang"
    ],
    "published_date": "2026-02-25T04:18:18Z",
    "abstract": "High-resolution structure determination by cryo-electron microscopy (cryo-EM) requires the accurate fitting of an atomic model into an experimental density map. Traditional refinement pipelines such as Phenix.real_space_refine and Rosetta are computationally expensive, demand extensive manual tuning, and present a significant bottleneck for researchers. We present CryoNet.Refine, an end-to-end deep learning framework that automates and accelerates molecular structure refinement. Our approach utilizes a one-step diffusion model that integrates a density-aware loss function with robust stereochemical restraints, enabling rapid optimization of a structure against experimental data. CryoNet.Refine provides a unified and versatile solution capable of refining protein complexes as well as DNA/RNA-protein complexes. In benchmarks against Phenix.real_space_refine, CryoNet.Refine consistently achieves substantial improvements in both model-map correlation and overall geometric quality metrics. By offering a scalable, automated, and powerful alternative, CryoNet.Refine aims to serve as an essential tool for next-generation cryo-EM structure refinement. Web server: https://cryonet.ai/refine; Source code: https://github.com/kuixu/cryonet.refine.",
    "pdf_link": "https://arxiv.org/pdf/2602.22263v1",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "eess.IV",
      "q-bio.QM"
    ],
    "tldr": "CryoNet.Refine is a one-step diffusion model that automates cryo-EM atomic structure refinement against experimental density maps, outperforming Phenix.real_space_refine on model-map correlation and geometric quality.",
    "keywords": [
      "One-Step Diffusion Model",
      "Cryo-EM Structure Refinement",
      "Density-Aware Loss Function",
      "Stereochemical Restraint Optimization",
      "Atomic Model Fitting"
    ],
    "relevance_score": 9
  },
  {
    "id": "2602.21648v1",
    "title": "Multimodal Survival Modeling and Fairness-Aware Clinical Machine Learning for 5-Year Breast Cancer Risk Prediction",
    "authors": [
      "Toktam Khatibi"
    ],
    "published_date": "2026-02-25T07:20:43Z",
    "abstract": "Clinical risk prediction models often underperform in real-world settings due to poor calibration, limited transportability, and subgroup disparities. These challenges are amplified in high-dimensional multimodal cancer datasets characterized by complex feature interactions and a p >> n structure. We present a fully reproducible multimodal machine learning framework for 5-year overall survival prediction in breast cancer, integrating clinical variables with high-dimensional transcriptomic and copy-number alteration (CNA) features from the METABRIC cohort. After variance- and sparsity-based filtering and dimensionality reduction, models were trained using stratified train/validation/test splits with validation-based hyperparameter tuning. Two survival approaches were compared: an elastic-net regularized Cox model (CoxNet) and a gradient-boosted survival tree model implemented using XGBoost. CoxNet provides embedded feature selection and stable estimation, whereas XGBoost captures nonlinear effects and higher-order interactions. Performance was assessed using time-dependent area under the ROC curve (AUC), average precision (AP), calibration curves, Brier score, and bootstrapped 95 percent confidence intervals. CoxNet achieved validation and test AUCs of 98.3 and 96.6, with AP values of 90.1 and 80.4. XGBoost achieved validation and test AUCs of 98.6 and 92.5, with AP values of 92.5 and 79.9. Fairness diagnostics showed stable discrimination across age groups, estrogen receptor status, molecular subtypes, and menopausal state. This work introduces a governance-oriented multimodal survival framework emphasizing calibration, fairness auditing, robustness, and reproducibility for high-dimensional clinical machine learning.",
    "pdf_link": "https://arxiv.org/pdf/2602.21648v1",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "tldr": "A multimodal framework compares elastic-net Cox regression (CoxNet) and XGBoost for 5-year breast cancer survival prediction on METABRIC transcriptomic data, with fairness auditing across demographic subgroups.",
    "keywords": [
      "Cox Proportional Hazards Model (CoxNet)",
      "XGBoost Gradient Boosting",
      "Time-Dependent AUC Evaluation",
      "Elastic-Net Regularization",
      "Fairness-Aware Modeling"
    ],
    "relevance_score": 8
  },
  {
    "id": "2602.21993v1",
    "title": "Prediction of source nutrients for microorganisms using metabolic networks",
    "authors": [
      "Olivia Bulka",
      "Chabname Ghassemi Nedjad",
      "Loïc Paulevé",
      "Sylvain Prigent",
      "Clémence Frioux"
    ],
    "published_date": "2026-02-25T15:13:07Z",
    "abstract": "Metagenomics has lowered the barrier to microbial discovery--enabling the identification of novel microbes without isolation--but cultures remain imperative for the deep study of microbes. Cultivation and isolation of non-model microbes remains a major challenge, despite advances in high-throughput culturomic methods. The quantity of simultaneous experimental variables is constrained by time and resources, but the list can be reduced using computational biology. Given an annotated genome, metabolic modelling can be used to predict source nutrients required for the growth of a microbe, which acts as an initial screen to inform culture and isolation experiments. This chapter provides an overview of metabolic networks and modelling and how they can be used to predict the nutrient requirements of a microorganism, followed by a sample protocol using a toy metabolic network, which is then expanded to a genome-scale metabolic network application. These methods can be applied to any metabolic network of interest--which in turn can be created from any genome of interest--and are a starting point for experimental validation of source nutrients required for microorganisms that remain uncultivated to date.",
    "pdf_link": "https://arxiv.org/pdf/2602.21993v1",
    "categories": [
      "q-bio.MN",
      "q-bio.QM"
    ],
    "tldr": "Genome-scale metabolic network modeling computationally predicts source nutrients for microbial growth, providing a screen to guide cultivation experiments for previously uncultivated microorganisms.",
    "keywords": [
      "Genome-Scale Metabolic Models",
      "Flux Balance Analysis",
      "Constraint-Based Modeling",
      "Genome Annotation-Based Cultivation Prediction",
      "Metabolic Network Reconstruction"
    ],
    "relevance_score": 8
  },
  {
    "id": "2602.21393v1",
    "title": "An information-based model selection criterion for data-driven model discovery",
    "authors": [
      "Michael C Chung",
      "Alen Zacharia",
      "Juan Guan"
    ],
    "published_date": "2026-02-24T21:45:10Z",
    "abstract": "Data-driven model discovery (DDMD) algorithms are powerful tools for extracting interpretable symbolic models from data. However, identifying the model that best balances goodness-of-fit and sparsity is often a laborious process requiring user fine-tuning, is prone to overfitting, and results may significantly vary depending on model initialization and specific training procedure. Here, we present a sparse regression algorithm that automatically and adaptively generates candidate models, and uses a novel sample-length-scaling logarithmic information criterion (SLIC) to identify the best model from these candidates. We demonstrate that SLIC greatly outperforms other popular information criteria in extracting the correct model from the data of several nonlinear ordinary and partial differential equations. Then, we demonstrate SLIC's ability to discover interpretable models from experimental datasets in fluid dynamics and nanotechnology that generate new testable predictions.",
    "pdf_link": "https://arxiv.org/pdf/2602.21393v1",
    "categories": [
      "q-bio.QM"
    ],
    "tldr": "A sparse regression algorithm with the novel Sample-Length-Scaling Information Criterion (SLIC) automates model selection for data-driven discovery of nonlinear ODEs and PDEs, outperforming AIC and BIC.",
    "keywords": [
      "Sparse Regression",
      "Sample-Length-Scaling Information Criterion (SLIC)",
      "Symbolic Regression",
      "SINDy",
      "Nonlinear Dynamical Systems"
    ],
    "relevance_score": 7
  },
  {
    "id": "2602.23324v1",
    "title": "Discrete turn strategies emerge in information-limited navigation",
    "authors": [
      "Jose M. Betancourt",
      "Matthew P. Leighton",
      "Thierry Emonet",
      "Benjamin B. Machta",
      "Michael C. Abbott"
    ],
    "published_date": "2026-02-26T18:32:51Z",
    "abstract": "Navigation up a sensory gradient is one of the simplest behaviours, and the simplest strategy is run and tumble. But some organisms use other strategies, such as reversing direction or turning by some angle. Here we ask what drives the choice of strategy, which we frame as maximising up-gradient speed using a given amount of sensory information per unit time. We find that, without directional information on which way to turn, behavioural strategies which make sudden turns perform better than gradual steering. We see various transitions where a different strategy becomes optimal, such as a switch from reversing direction to fully re-orienting tumbles as more information becomes available. And, among more complex re-orientation strategies, we show that discrete turn angles are best, and see transitions in how many such angles the optimal strategy employs.",
    "pdf_link": "https://arxiv.org/pdf/2602.23324v1",
    "categories": [
      "physics.bio-ph",
      "cond-mat.stat-mech",
      "q-bio.QM"
    ],
    "tldr": "Information-theoretic optimization shows discrete turn-angle strategies outperform gradual steering under sensory constraints, with phase transitions between reversals, tumbles, and multi-angle optimal strategies.",
    "keywords": [
      "Shannon Information Rate",
      "Optimal Control",
      "Run-And-Tumble Dynamics",
      "Gradient Navigation",
      "Behavioral Strategy Optimization"
    ],
    "relevance_score": 7
  },
  {
    "id": "2602.22673v1",
    "title": "Forecasting Antimicrobial Resistance Trends Using Machine Learning on WHO GLASS Surveillance Data: A Retrieval-Augmented Generation Approach for Policy Decision Support",
    "authors": [
      "Md Tanvir Hasan Turja"
    ],
    "published_date": "2026-02-26T06:45:08Z",
    "abstract": "Antimicrobial resistance (AMR) is a growing global crisis projected to cause 10 million deaths per year by 2050. While the WHO Global Antimicrobial Resistance and Use Surveillance System (GLASS) provides standardized surveillance data across 44 countries, few studies have applied machine learning to forecast population-level resistance trends from this data. This paper presents a two-component framework for AMR trend forecasting and evidence-grounded policy decision support. We benchmark six models -- Naive, Linear Regression, Ridge Regression, XGBoost, LightGBM, and LSTM -- on 5,909 WHO GLASS observations across six WHO regions (2021-2023). XGBoost achieved the best performance with a test MAE of 7.07% and R-squared of 0.854, outperforming the naive baseline by 83.1%. Feature importance analysis identified the prior-year resistance rate as the dominant predictor (50.5% importance), while regional MAE ranged from 4.16% (European Region) to 10.14% (South-East Asia Region). We additionally implemented a Retrieval-Augmented Generation (RAG) pipeline combining a ChromaDB vector store of WHO policy documents with a locally deployed Phi-3 Mini language model, producing source-attributed, hallucination-constrained policy answers. Code and data are available at https://github.com/TanvirTurja",
    "pdf_link": "https://arxiv.org/pdf/2602.22673v1",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "tldr": "XGBoost best forecasts population-level antimicrobial resistance (R²=0.854) across WHO GLASS data; a Retrieval-Augmented Generation pipeline with ChromaDB provides evidence-grounded policy decision support.",
    "keywords": [
      "XGBoost",
      "LightGBM",
      "Long Short-Term Memory (LSTM)",
      "Ridge Regression",
      "Retrieval-Augmented Generation (RAG)"
    ],
    "relevance_score": 7
  }
]