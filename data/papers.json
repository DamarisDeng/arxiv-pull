[
  {
    "id": "2602.21993v1",
    "title": "Prediction of source nutrients for microorganisms using metabolic networks",
    "authors": [
      "Olivia Bulka",
      "Chabname Ghassemi Nedjad",
      "Loïc Paulevé",
      "Sylvain Prigent",
      "Clémence Frioux"
    ],
    "published_date": "2026-02-25T15:13:07Z",
    "abstract": "Metagenomics has lowered the barrier to microbial discovery--enabling the identification of novel microbes without isolation--but cultures remain imperative for the deep study of microbes. Cultivation and isolation of non-model microbes remains a major challenge, despite advances in high-throughput culturomic methods. The quantity of simultaneous experimental variables is constrained by time and resources, but the list can be reduced using computational biology. Given an annotated genome, metabolic modelling can be used to predict source nutrients required for the growth of a microbe, which acts as an initial screen to inform culture and isolation experiments. This chapter provides an overview of metabolic networks and modelling and how they can be used to predict the nutrient requirements of a microorganism, followed by a sample protocol using a toy metabolic network, which is then expanded to a genome-scale metabolic network application. These methods can be applied to any metabolic network of interest--which in turn can be created from any genome of interest--and are a starting point for experimental validation of source nutrients required for microorganisms that remain uncultivated to date.",
    "pdf_link": "https://arxiv.org/pdf/2602.21993v1",
    "categories": [
      "q-bio.MN",
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.21648v1",
    "title": "Multimodal Survival Modeling and Fairness-Aware Clinical Machine Learning for 5-Year Breast Cancer Risk Prediction",
    "authors": [
      "Toktam Khatibi"
    ],
    "published_date": "2026-02-25T07:20:43Z",
    "abstract": "Clinical risk prediction models often underperform in real-world settings due to poor calibration, limited transportability, and subgroup disparities. These challenges are amplified in high-dimensional multimodal cancer datasets characterized by complex feature interactions and a p >> n structure. We present a fully reproducible multimodal machine learning framework for 5-year overall survival prediction in breast cancer, integrating clinical variables with high-dimensional transcriptomic and copy-number alteration (CNA) features from the METABRIC cohort. After variance- and sparsity-based filtering and dimensionality reduction, models were trained using stratified train/validation/test splits with validation-based hyperparameter tuning. Two survival approaches were compared: an elastic-net regularized Cox model (CoxNet) and a gradient-boosted survival tree model implemented using XGBoost. CoxNet provides embedded feature selection and stable estimation, whereas XGBoost captures nonlinear effects and higher-order interactions. Performance was assessed using time-dependent area under the ROC curve (AUC), average precision (AP), calibration curves, Brier score, and bootstrapped 95 percent confidence intervals. CoxNet achieved validation and test AUCs of 98.3 and 96.6, with AP values of 90.1 and 80.4. XGBoost achieved validation and test AUCs of 98.6 and 92.5, with AP values of 92.5 and 79.9. Fairness diagnostics showed stable discrimination across age groups, estrogen receptor status, molecular subtypes, and menopausal state. This work introduces a governance-oriented multimodal survival framework emphasizing calibration, fairness auditing, robustness, and reproducibility for high-dimensional clinical machine learning.",
    "pdf_link": "https://arxiv.org/pdf/2602.21648v1",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.21393v1",
    "title": "An information-based model selection criterion for data-driven model discovery",
    "authors": [
      "Michael C Chung",
      "Alen Zacharia",
      "Juan Guan"
    ],
    "published_date": "2026-02-24T21:45:10Z",
    "abstract": "Data-driven model discovery (DDMD) algorithms are powerful tools for extracting interpretable symbolic models from data. However, identifying the model that best balances goodness-of-fit and sparsity is often a laborious process requiring user fine-tuning, is prone to overfitting, and results may significantly vary depending on model initialization and specific training procedure. Here, we present a sparse regression algorithm that automatically and adaptively generates candidate models, and uses a novel sample-length-scaling logarithmic information criterion (SLIC) to identify the best model from these candidates. We demonstrate that SLIC greatly outperforms other popular information criteria in extracting the correct model from the data of several nonlinear ordinary and partial differential equations. Then, we demonstrate SLIC's ability to discover interpretable models from experimental datasets in fluid dynamics and nanotechnology that generate new testable predictions.",
    "pdf_link": "https://arxiv.org/pdf/2602.21393v1",
    "categories": [
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.20495v1",
    "title": "Unveiling Scaling Laws of Parameter Identifiability and Uncertainty Quantification in Data-Driven Biological Modeling",
    "authors": [
      "Shun Wang",
      "Wenrui Hao"
    ],
    "published_date": "2026-02-24T02:51:05Z",
    "abstract": "Integrating high-dimensional biological data into data-driven mechanistic modeling requires rigorous practical identifiability to ensure interpretability and generalizability. However, coordinate identifiability analysis often suffers from numerical instabilities near singular local minimizers. We present a computational framework that uncovers fundamental scaling laws governing practical identifiability through asymptotic analysis. By synthesizing Fisher information with perturbed Hessian matrices, we establish a hierarchical approach to quantify coordinate identifiability and inform uncertainty quantification within non-identifiable subspaces across different orders. Supported by rigorous mathematical analysis and validated on synthetic and real-world data, our framework was applied to HIV-host dynamics and spatiotemporal amyloid-beta propagation. These applications demonstrate the framework's efficiency in elucidating critical mechanisms underlying HIV diagnostics and Alzheimer's disease progression. In the era of large-scale mechanistic digital twins, our framework provides the scaling laws for data-driven modeling in terms of both parameter identifiability and uncertainty, ensuring that data-driven inferences are grounded in verifiable biological reality.",
    "pdf_link": "https://arxiv.org/pdf/2602.20495v1",
    "categories": [
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.20344v1",
    "title": "Hierarchical Molecular Representation Learning via Fragment-Based Self-Supervised Embedding Prediction",
    "authors": [
      "Jiele Wu",
      "Haozhe Ma",
      "Zhihan Guo",
      "Thanh Vinh Vo",
      "Tze Yun Leong"
    ],
    "published_date": "2026-02-23T20:41:44Z",
    "abstract": "Graph self-supervised learning (GSSL) has demonstrated strong potential for generating expressive graph embeddings without the need for human annotations, making it particularly valuable in domains with high labeling costs such as molecular graph analysis. However, existing GSSL methods mostly focus on node- or edge-level information, often ignoring chemically relevant substructures which strongly influence molecular properties. In this work, we propose Graph Semantic Predictive Network (GraSPNet), a hierarchical self-supervised framework that explicitly models both atomic-level and fragment-level semantics. GraSPNet decomposes molecular graphs into chemically meaningful fragments without predefined vocabularies and learns node- and fragment-level representations through multi-level message passing with masked semantic prediction at both levels. This hierarchical semantic supervision enables GraSPNet to learn multi-resolution structural information that is both expressive and transferable. Extensive experiments on multiple molecular property prediction benchmarks demonstrate that GraSPNet learns chemically meaningful representations and consistently outperforms state-of-the-art GSSL methods in transfer learning settings.",
    "pdf_link": "https://arxiv.org/pdf/2602.20344v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.20289v1",
    "title": "The Sim-to-Real Gap in MRS Quantification: A Systematic Deep Learning Validation for GABA",
    "authors": [
      "Zien Ma",
      "S. M. Shermer",
      "Oktay Karakuş",
      "Frank C. Langbein"
    ],
    "published_date": "2026-02-23T19:16:03Z",
    "abstract": "Magnetic resonance spectroscopy (MRS) is used to quantify metabolites in vivo and estimate biomarkers for conditions ranging from neurological disorders to cancers. Quantifying low-concentration metabolites such as GABA ($γ$-aminobutyric acid) is challenging due to low signal-to-noise ratio (SNR) and spectral overlap. We investigate and validate deep learning for quantifying complex, low-SNR, overlapping signals from MEGA-PRESS spectra, devise a convolutional neural network (CNN) and a Y-shaped autoencoder (YAE), and select the best models via Bayesian optimisation on 10,000 simulated spectra from slice-profile-aware MEGA-PRESS simulations. The selected models are trained on 100,000 simulated spectra. We validate their performance on 144 spectra from 112 experimental phantoms containing five metabolites of interest (GABA, Glu, Gln, NAA, Cr) with known ground truth concentrations across solution and gel series acquired at 3 T under varied bandwidths and implementations. These models are further assessed against the widely used LCModel quantification tool. On simulations, both models achieve near-perfect agreement (small MAEs; regression slopes $\\approx 1.00$, $R^2 \\approx 1.00$). On experimental phantom data, errors initially increased substantially. However, modelling variable linewidths in the training data significantly reduced this gap. The best augmented deep learning models achieved a mean MAE for GABA over all phantom spectra of 0.151 (YAE) and 0.160 (FCNN) in max-normalised relative concentrations, outperforming the conventional baseline LCModel (0.220). A sim-to-real gap remains, but physics-informed data augmentation substantially reduced it. Phantom ground truth is needed to judge whether a method will perform reliably on real data.",
    "pdf_link": "https://arxiv.org/pdf/2602.20289v1",
    "categories": [
      "eess.SP",
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "id": "2602.19775v1",
    "title": "Exact Discrete Stochastic Simulation with Deep-Learning-Scale Gradient Optimization",
    "authors": [
      "Jose M. G. Vilar",
      "Leonor Saiz"
    ],
    "published_date": "2026-02-23T12:29:43Z",
    "abstract": "Exact stochastic simulation of continuous-time Markov chains (CTMCs) is essential when discreteness and noise drive system behavior, but the hard categorical event selection in Gillespie-type algorithms blocks gradient-based learning. We eliminate this constraint by decoupling forward simulation from backward differentiation, with hard categorical sampling generating exact trajectories and gradients propagating through a continuous massively-parallel Gumbel-Softmax straight-through surrogate. Our approach enables accurate optimization at parameter scales over four orders of magnitude beyond existing simulators. We validate for accuracy, scalability, and reliability on a reversible dimerization model (0.09% error), a genetic oscillator (1.2% error), a 203,796-parameter gene regulatory network achieving 98.4% MNIST accuracy (a prototypical deep-learning multilayer perceptron benchmark), and experimental patch-clamp recordings of ion channel gating (R^2 = 0.987) in the single-channel regime. Our GPU implementation delivers 1.9 billion steps per second, matching the scale of non-differentiable simulators. By making exact stochastic simulation massively parallel and autodiff-compatible, our results enable high-dimensional parameter inference and inverse design across systems biology, chemical kinetics, physics, and related CTMC-governed domains.",
    "pdf_link": "https://arxiv.org/pdf/2602.19775v1",
    "categories": [
      "q-bio.QM",
      "cond-mat.stat-mech",
      "cs.LG",
      "physics.comp-ph",
      "q-bio.MN"
    ]
  },
  {
    "id": "2602.20218v1",
    "title": "Targeted T2-FLAIR Dropout Training Improves Robustness of nnU-Net Glioblastoma Segmentation to Missing T2-FLAIR",
    "authors": [
      "Marco Öchsner",
      "Lena Kaiser",
      "Robert Stahl",
      "Nathalie L. Albert",
      "Thomas Liebig",
      "Robert Forbrig",
      "Jonas Reis"
    ],
    "published_date": "2026-02-23T08:51:19Z",
    "abstract": "Purpose: To determine whether targeted T2 fluid-attenuated inversion recovery (T2-FLAIR) dropout training improves glioblastoma MRI tumor segmentation robustness to missing T2-FLAIR without degrading performance when T2-FLAIR is available. Materials and Methods: This retrospective multi-dataset study developed nnU-Net models on BraTS 2021 (n=848) and externally tested them on UPenn-GBM glioblastoma MRI (n=403; 2006-2018; age 18-89 years; 60% male). Models were trained with no dropout or targeted T2-FLAIR dropout (probability rate r=0.35 or 0.50) by replacing only the T2-FLAIR channel with zeros. Inference used T2-FLAIR-present and T2-FLAIR-absent scenarios (T2-FLAIR set to zero). The primary endpoint was Dice similarity coefficient (DSC); secondary endpoints were 95th percentile Hausdorff distance and Bland-Altman whole-tumor volume bias. Equivalence was assessed with two one-sided tests using +/-1.5 DSC percentage points, and noninferiority versus HD-GLIO used a -1.5-point margin. Results: With T2-FLAIR present, median overall DSC was 94.8% (interquartile range, 90.0%-97.1%) with dropout and 95.0% (interquartile range, 90.3%-97.1%) without dropout (equivalence supported, p<0.001). With T2-FLAIR absent, median overall DSC improved from 81.0% (interquartile range, 75.1%-86.4%) without dropout to 93.4% (interquartile range, 89.1%-96.2%) with dropout (r=0.35); edema DSC improved from 14.0% to 87.0%, edema 95th percentile Hausdorff distance improved from 22.44 mm to 2.45 mm, and whole-tumor volume bias improved from -45.6 mL to 0.83 mL. Dropout was noninferior to HD-GLIO under T2-FLAIR-present (all p<0.001). Conclusion: Targeted T2-FLAIR dropout preserved segmentation performance when T2-FLAIR was available and reduced segmentation error and whole-tumor volume bias when T2-FLAIR was absent.",
    "pdf_link": "https://arxiv.org/pdf/2602.20218v1",
    "categories": [
      "eess.IV",
      "q-bio.QM"
    ]
  }
]
